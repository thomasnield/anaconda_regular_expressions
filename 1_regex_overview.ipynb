{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86fa7a42",
   "metadata": {},
   "source": [
    "# Regular Expressions Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588995b4",
   "metadata": {},
   "source": [
    "If you have done any work in Python, especially in the domains of data science, machine learning, language modeling, and data engineering there is a good chance you have encountered regular expressions. \n",
    "\n",
    "**Regular expressions** are a powerful tool for matching patterns in text data. They are universally supported across hundreds of platforms inside and outside of Python. If you have ever used wildcards to match text, think of them as wildcards on steroids. With only a few hours of learning, and consistent use and practice, you can leverage this powerful convention to wrangle text. In natural language processing, regular expressions are especially important for the tokenization of data and cleaning it. However, they can be used for the simple and yet tedious mundane tasks, like finding and replacing text or splitting text on unusual separators. Other programming languages like Java, Go, R, C#, C++, and SQL support regular expressions which give them extra utility. \n",
    "\n",
    "From providing a better *search and replace* to removing unwanted tokens, regular expressions are a skill you can use every day to shred through the most daunting of text processing tasks. If you frequently find yourself manually scanning documents or parsing substrings just to identify text patterns, you might want to give them a try!\n",
    "\n",
    "Check this out. In this notebook, go to *Edit -> Find and Replace* and you will see a subtle button that allows you to search a notebook using regular expressions. We can search for the words \"support\" and \"supported\" in this document using a single regular expression `support(ed)?`. \n",
    "\n",
    "![](media/3dLWAqeB.png)\n",
    "\n",
    "You will find this regex option for *search and replace*  in most code text editors as well, like Visual Studio Code, Notepad++, eMacs, Vim, and Pycharm. You will find them supported in other data analytics tools like Alteryx, Tableau, and LibreOffice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7a380",
   "metadata": {},
   "source": [
    "## A Motivational Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed10dff",
   "metadata": {},
   "source": [
    "Think of regular expressions as a mini programming language within programming languages. Python has regular expression support built right into its standard library using the `re` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f59e7b",
   "metadata": {},
   "source": [
    "Let's do a simple match check. Supposed we wanted to only match the strings \"Support\" and \"Supported\". Rather than write a whole bunch of inflexible and messy substring code, we can have a regular expression `Support(ed)?` do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bfa583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if re.fullmatch(pattern=\"Support(ed)?\", string=\"Support\"): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c5d1b",
   "metadata": {},
   "source": [
    "Do not worry if you do not understand the `pattern` syntax. We will learn everything about regular expression pattern syntax in this course.\n",
    "\n",
    "We can omit the `pattern` and the `string` parameter keywords as they are the first two arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57068851",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.fullmatch(\"Support(ed)?\",\"Support\"): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacfe331",
   "metadata": {},
   "source": [
    "Obviously, this will not match \"Supportability\" because that does not match our regular expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58682c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.fullmatch(pattern=\"Support(ed)?\", string=\"Supportability\"): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d1d4d1",
   "metadata": {},
   "source": [
    "Nor will it match a lowercase since that is not in the regular expression either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbff7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.fullmatch(pattern=\"Support(ed)?\", string=\"support\"): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c5030",
   "metadata": {},
   "source": [
    "Now we could develop a regular expression to allow the \"S\" to be uppercase or lowercase, as well as match \"Supportability\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.fullmatch(pattern=\"[Ss]upport(ability|ed)?\", string=\"supportability\"): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837d6017",
   "metadata": {},
   "source": [
    "Or we could just use the `flags` paramter and tell it to ignore alphabetic case altogether using `IGNORECASE`. We can also match any word that starts with \"support\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bae8ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if re.fullmatch(pattern=\"support.*\", string=\"Supportability\", flags=re.IGNORECASE): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d10ca25",
   "metadata": {},
   "source": [
    "The `re` module [supports a lot of different flags](https://docs.python.org/3/library/re.html#flags), and they can be helpful. However, the regular expression does most of the heavy lifting in controlling the pattern. But they are still worth looking at and we will use them as necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae67c8a",
   "metadata": {},
   "source": [
    "Hopefully this gives you a little taste of what regular expressions can do. Although the syntax might look alien and foreign to you right now, do you see how little code we typed and were able to adapt the patterns quickly? Imagine trying to use Python substrings which you may have done in the past!\n",
    "\n",
    "![Source: [XKCD.com](https://xkcd.com/208/)](https://imgs.xkcd.com/comics/regular_expressions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf593fe",
   "metadata": {},
   "source": [
    "[Source: XKCD.com](https://xkcd.com/208/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdb9f9",
   "metadata": {},
   "source": [
    "## Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d13bcf",
   "metadata": {},
   "source": [
    "So what are the use cases for regular expressions? There are many. Here are just a few examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed3e549",
   "metadata": {},
   "source": [
    "* Validating a user form input, like matching email address or phone number format\n",
    "\n",
    "* Searching SQL dumps for table definitions\n",
    "\n",
    "* Finding and replacing deprecated code with certain naming conventions\n",
    "\n",
    "* Creating custom tokenizers for language models and machine learning \n",
    "\n",
    "* Removing social security numbers, credit card numbers, and other sensitive info out of documents\n",
    "\n",
    "\n",
    "There is a lot of versatility. Here's a real world example. I need to search a document for all variants of a product, a microchip called the [Atmega32U4](https://www.digikey.com/en/products/filter/microcontrollers/685?s=N4IgTCBcDaIIIBUCyBRA4nAzGAqgFhAF0BfIA). But oh no, there are so many variants! \n",
    "\n",
    "* Atmega32u4\n",
    "\n",
    "* Atmega16u4\n",
    "\n",
    "* Atmega32u4-AUR\n",
    "\n",
    "* Atmega32u4RC-AUR\n",
    "\n",
    "* Atmega16u4-AUR\n",
    "\n",
    "* Atmega32u4-AU\n",
    "\n",
    "* Atmega32u4RC-AU\n",
    "\n",
    "* Atmega16u4-AU\n",
    "\n",
    "* Atmega32u4-MU\n",
    "\n",
    "* Atmega32u4RC-MU\n",
    "\n",
    "* Atmega16u4-MU\n",
    "\n",
    "Trying to create *if-then* code to match these product variants sounds terrible. It's a nightmare. Thankfully, we can have a regular expression come to the rescue. This regular expression pattern below will match all these product codes, and will not match anything else. \n",
    "\n",
    "```\n",
    "atmega(16|32)u4(rc)?(-[AM][MU]R?)?\n",
    "```\n",
    "\n",
    "Note below we test each of these product codes. We also throw in a fictitious product code \"Atmega17u4-MU\" that shold not qualify as it does not exist. Notice how all of these match except for the made-up product. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bf9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nums = [\"Atmega32u4\",\"Atmega16u4\",\"Atmega32u4-AUR\",\"Atmega32u4RC-AUR\",\n",
    "              \"Atmega16u4-AUR\",\"Atmega32u4-AU\",\"Atmega32u4RC-AU\",\"Atmega16u4-AU\",\n",
    "              \"Atmega32u4-MU\",\"Atmega32u4RC-MU\",\"Atmega16u4-MU\", \"Atmega17u4-MU\"]\n",
    "\n",
    "for model_num in model_nums: \n",
    "    if re.fullmatch(pattern=\"atmega(16|32)u4(rc)?(-[AM][MU]R?)?\", string=model_num, flags=re.IGNORECASE): \n",
    "        print(f\"{model_num} -> Match!\")\n",
    "    else: \n",
    "        print(f\"{model_num} -> No Match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa5e01f",
   "metadata": {},
   "source": [
    "There is one weakness in this regular expression. It will allow the \"16\" to attach to other patterns that it never belonged to. For example, we don't have an `Atmega16u4RC-MU` in our original list of products and this will result in a match. But for our purposes, that's okay. We can certainly make the regular expression more complex to capture this, but for our purposes this is okay. This brings us to the golden rule of regular expressions: MAKE A REGEX JUST COMPLEX AND SPECIFIC ENOUGH TO DO YOUR TASK. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f555474",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a85e79",
   "metadata": {},
   "source": [
    "Hopefully this got you motivated and excited to learn regular expressions. They will serve you well in your career and can be used daily even when you are doing simple tasks like word processing. That *Find and Replace* feature will never be the same to you. But as we go through this course, you will not only learn how to build regular expressions to match your specific text pattern needs but also a handful of libraries and real-world examples. \n",
    "\n",
    "Note that regular expressions can add a little bit of overhead to your compute. But computers are so blazing fast nowadays and for most everyday tasks, they are worth the compute expense you will likely not notice. That being said, you probably should be mindful when using regular expressions at big data scales and note they may slow down data pipelines. If you encounter this, you can find opportunities to optimize and engineer a better compilation or implementation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0755b43",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cc87a",
   "metadata": {},
   "source": [
    "Complete the code below by replacing the question marks to match the regular expression `[A-Z]{3}` against the string `DFW`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5485c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ? \n",
    "\n",
    "if ?.fullmatch(?, ?, flags=re.IGNORECASE): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f15b6",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bd8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "if re.fullmatch(pattern=\"[A-Z]{3}\", string=\"DFW\", flags=re.IGNORECASE): \n",
    "    print(\"Match!\")\n",
    "else: \n",
    "    print(\"No match!\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
