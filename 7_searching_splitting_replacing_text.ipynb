{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adc9994",
   "metadata": {},
   "source": [
    "# Searching, Splitting, and Replacing Text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5d341",
   "metadata": {},
   "source": [
    "In the previous sections we mastered the fundamentals of regular expressions. Now let's see how we can use this knowledge to accomplish some common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56474e4a",
   "metadata": {},
   "source": [
    "## Compiling a Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7ae928",
   "metadata": {},
   "source": [
    "Previously we used shorthand functions like `match`, `fullmatch`, and `search` from the `re` package. While these are fine for one-off matches, there will be situations where you want to reuse a regular expression. A regular expression actually has to be compiled as a mini-program, meaning they can be expensive to set up and use. This is why when you intend to use a regular expression multiple times you will want to compile and save it. \n",
    "\n",
    "Below we compile a regular expression that looks for websites that may be `http` or `https` and end with `.com`, `.org,` or `.gov`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e542551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "web_pattern = re.compile(r'(https?://)?(www\\.)?([a-z0-9]+)\\.(com|org|gov)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2841b136",
   "metadata": {},
   "source": [
    "We can now use this compiled and reusable `Pattern` object for multiple tasks. We can, for example, pass it to a `pattern` argument in place of a string. This way `fullmatch` will not waste any time doing compilation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f5c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.fullmatch(pattern=web_pattern, string=\"https://www.anaconda.com\") != None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab838a4",
   "metadata": {},
   "source": [
    "## Scanning a Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f3875",
   "metadata": {},
   "source": [
    "If we imported a document into a string, we can use the `finditer()` function on a `Pattern` object to find multiple [`Match` objects](https://docs.python.org/3/library/re.html#re.Match) in that document. We can take those results and iterate them in a `for` loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49533579",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = \"\"\"\n",
    "Here are a few websites below: \n",
    "\n",
    "https://www.yawmanflight.com\n",
    "http://microsoft.com\n",
    "https://youtube.com\n",
    "https://www.anaconda.com\n",
    "\n",
    "These are non-commercial sites: \n",
    "https://www.python.org\n",
    "https://whitehouse.gov \n",
    "\"\"\"\n",
    "\n",
    "matches = web_pattern.finditer(urls)\n",
    "\n",
    "for match in matches:\n",
    "    print(match[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919aebee",
   "metadata": {},
   "source": [
    "Something that is interesting is `match[0]` will return the full match. But indices after that will return the group match as indexed by each pair of parantheses `( )`. For example, the fourth group of parantheses `(com|org|gov)` in our pattern will return that web domain. We can access it using `match[4]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c1164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = web_pattern.finditer(urls)\n",
    "\n",
    "for match in matches:\n",
    "    print(match[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7464b",
   "metadata": {},
   "source": [
    "Read more in the [Match object documentation](https://docs.python.org/3/library/re.html#re.Match) to learn about other methods available. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158c6b9",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737e7f4c",
   "metadata": {},
   "source": [
    "Regular expressions can offer some interesting capabilities when it comes to splitting data. \n",
    "\n",
    "Let's load up the famous machine learning Iris dataset. While typically we would use Pandas to load tabular data (which we will discuss in the next section), let's learn a few tricks from scratch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6aec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    r\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/classification/iris.csv\",\n",
    "    \"iris.csv\"\n",
    ")\n",
    "\n",
    "filename = 'iris.csv' \n",
    "file = open(filename, encoding=\"utf-8\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ca7d0",
   "metadata": {},
   "source": [
    "So we loaded that entire dataset into a single string `text`. It is common to split on new lines followed by comma separated values for each row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646df1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in text.split(\"\\n\"):\n",
    "    print(row.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95799417",
   "metadata": {},
   "source": [
    "But what if we wanted to only separate the last column with the species? There is an opportunity to use a regular expression as our separator. We can use a `,` followed by a suffix `(?=[a-z]+$)` to match only commas that are followed by lowercase alphabetic characters `[a-z]+` and then an end-of-string `$`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b2469",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pattern = re.compile(r\",(?=[a-z]+$)\")\n",
    "\n",
    "for row in text.split(\"\\n\"):\n",
    "    print(re.split(split_pattern, row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda9596",
   "metadata": {},
   "source": [
    "Perfect! With regular expressions you can split strings on much more elaborate and context-driven separators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762d075",
   "metadata": {},
   "source": [
    "## Replacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e960fdf",
   "metadata": {},
   "source": [
    "Let's return to our previous example with the websites. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = \"\"\"\n",
    "Here are a few websites below: \n",
    "\n",
    "https://www.yawmanflight.com\n",
    "http://microsoft.com\n",
    "https://youtube.com\n",
    "https://www.anaconda.com\n",
    "\n",
    "These are non-commercial sites: \n",
    "https://www.python.org\n",
    "https://whitehouse.gov \n",
    "\"\"\"\n",
    "\n",
    "matches = web_pattern.finditer(urls)\n",
    "\n",
    "for match in matches:\n",
    "    print(match[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc51194",
   "metadata": {},
   "source": [
    "Let's say we wanted to clean up the document and replace the `http` with `https`. Obviously we do not want to replace the `http` that already exists in existing `https` strings, so we will make sure it is not followed by an \"s\". this can be done using a suffix using a suffix `(?=[^s])`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_https = re.sub(pattern=\"http(?=[^s])\", \n",
    "                   repl=\"https\", \n",
    "                   string=urls)\n",
    "print(fix_https)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9f26e",
   "metadata": {},
   "source": [
    "Note that there are [additional parameters](https://docs.python.org/3/library/re.html#re.sub) for flags as well as the `count` which is the maximum number of replacements to make. \n",
    "\n",
    "Now let's say we want to inject a `www.` where it is missing. To achieve this, we need what is called a **negative lookahead**, which is a suffix that *we do not want matched* to qualify. We will qualify two slashes `//` that are not followed by `www.`, which can be expressed as `(?!www)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bec510",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_www = re.sub(pattern=\"//(?!www)\", \n",
    "                   repl=\"//www.\", \n",
    "                   string=fix_https)\n",
    "print(fix_www)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537be6e8",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4e29a9",
   "metadata": {},
   "source": [
    "Split the string below to separate on commas but only if the commas exist between two digits. Replace the question mark `?` with the regular expression below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023186bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "split_pattern = re.compile(?)\n",
    "\n",
    "re.split(pattern=split_pattern, string=\"6.1,2.9,4.7,1.4,versicolor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361632e",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb013959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "split_pattern = re.compile(\"(?<=[0-9]),(?=[0-9])\")\n",
    "\n",
    "re.split(pattern=split_pattern, string=\"6.1,2.9,4.7,1.4,versicolor\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
