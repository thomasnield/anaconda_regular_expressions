{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b17d92",
   "metadata": {},
   "source": [
    "# Regular Expressions in Pandas, SQL, and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a2316",
   "metadata": {},
   "source": [
    "In this section we will learn a few practical places we can apply regular expressions through Python libraries. Regular expressions are supported in many, many places but hopefully this will give an idea of how regular expressions can be used for common libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5aa254",
   "metadata": {},
   "source": [
    "## Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8cb05",
   "metadata": {},
   "source": [
    "When you import a CSV, you typically would use Pandas in a Python environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/classification/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f280d23",
   "metadata": {},
   "source": [
    "Recall in the last section how we manually separated only the `species` column from the rest of the data. We can achieve this using the `sep` argument and provide a regular expression. We will need to tell Pandas to use the `python` engine to handle the regular expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534c3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "pd.read_csv(url, sep=\",(?=[a-z]+$)\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b2cad",
   "metadata": {},
   "source": [
    "Going back to our original DataFrame with columns predictably separated, let's say we wanted to match a regular expression against a field. We can use the `str.match()` function to return a `Boolean` array of values, and then qualify only those records. Below we match only species that start with a `v` and the third character is an `r`, as specified by the regex `^v[a-z]r.*`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['species'].str.match(\"^v[a-z]r.*\") == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31402e",
   "metadata": {},
   "source": [
    "Sure enough we get records where the species are `versicolor` and `virginica`. \n",
    "\n",
    "This example may be slightly contrived, but we can also replace a regular expression pattern with different text. Below we take that regex pattern and replace those three latters with \"XXX\". This could be helpful if you are trying to replace sensitive information like social security numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa75e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['species'].str.replace(\"^v[a-z]r\", \"XXX\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5e2692",
   "metadata": {},
   "source": [
    "There are a lot of places that accept regular expressions in Pandas, so be sure to keep an eye out for regex-related parameters in the functions you use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c520f7",
   "metadata": {},
   "source": [
    "## SQL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8880fb4c",
   "metadata": {},
   "source": [
    "Another place you can leverage regular expressions is most mainstream SQL platforms like MySQL, PostgreSQL, Microsoft SQL Server, Oracle, and SQLite. Let's try it out on SQLite just to see this in action. Note that each SQL platform may implement regular expression function calls differently, just like Python and Java will have their own functions to match, replace, and split text using regular expressions. The regular expressions are largely the same across all platforms, but how you pass them via functions and operators will vary. \n",
    "\n",
    "Let's download and open a SQLite database, and query a `CUSTOMER` table. For good measure, we'll use Pandas to conveniently display the results in a `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49a834",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/thomasnield/anaconda_intro_to_sql/blob/main/company_operations.db?raw=true\", \"company_operations.db\")\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "\n",
    "\n",
    "sql = \"SELECT * FROM CUSTOMER\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d51333",
   "metadata": {},
   "source": [
    "While other SQL platforms are often ready-to-go to use regular expressions, we have to enable them with SQLite. To use a regular expression to match records on a given field, we need to implement the `REGEXP` function. Thankfully we can do this by simply passing a Python function to the SQLite connection by this name, and we are set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe06464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def regexp(pattern, string):\n",
    "    return 1 if re.search(pattern, string) else 0\n",
    "\n",
    "conn.create_function('regexp', 2, regexp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba4e79",
   "metadata": {},
   "source": [
    "Below we query records where the `ADDRESS` ends in `Dr` or `Ave`, which we capture with a regular expression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM CUSTOMER WHERE ADDRESS REGEXP '.*(Dr|Ave)$'\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1bfd5",
   "metadata": {},
   "source": [
    "While it will vary by SQL platform, you can expect to find functions to split and replace text using regular expression patterns as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c7077",
   "metadata": {},
   "source": [
    "# NLP using spaCy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58905a46",
   "metadata": {},
   "source": [
    "If you have ever dabbled in natural language processing (NLP), or explored how to build large language models, you will likely know that tokenization is a fundamental step to take text data and turn it into numeric data. \n",
    "\n",
    "Before we get started, let's get spaCy installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976c3ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install spacy \n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e0bce8",
   "metadata": {},
   "source": [
    "When you tokenize text data, you typically will tokenize words, names, and other dictionary-esque strings. But sometimes you may want to tokenize IP addresses, phone numbers, and other structurally-formatted values and perform custom matching on those. Maybe you want to match different variants or spellings of the same word, like favorite or favourite. \n",
    "\n",
    "We can use regular expresssions to aid spaCy in identifying phone numbers like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba269fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"My phone number is 742-278-0572\")\n",
    "\n",
    "expression = r\"[0-9]{3}-[0-9]{3}-[0-9]{4}\"\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f028a7",
   "metadata": {},
   "source": [
    "If you are familiar with spaCy, definitely check out the [documentation on rule-based matching](https://spacy.io/usage/rule-based-matching). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3af1ca",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a697be31",
   "metadata": {},
   "source": [
    "Find a way to modify the `DataFrame` below to filter only for records where the `STREET_ADDRESS` field has a 3-digit street number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e06092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/thomasnield/anaconda_intro_to_sql/blob/main/company_operations.db?raw=true\", \"company_operations.db\")\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "\n",
    "df = pd.read_sql(\"SELECT * FROM CUSTOMER\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db457e30",
   "metadata": {},
   "source": [
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda5bba",
   "metadata": {},
   "source": [
    "You can achieve this task in two ways, but both use the regex `^[0-9]{3}\\s`. \n",
    "\n",
    "Modify the SQL query to use regular expressions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b038959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/thomasnield/anaconda_intro_to_sql/blob/main/company_operations.db?raw=true\", \"company_operations.db\")\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "\n",
    "import re \n",
    "\n",
    "def regexp(pattern, string):\n",
    "    return 1 if re.search(pattern, string) else 0\n",
    "\n",
    "conn.create_function('regexp', 2, regexp)\n",
    "\n",
    "df = pd.read_sql(r\"SELECT * FROM CUSTOMER WHERE ADDRESS REGEXP '^[0-9]{3}\\s'\", conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298fa7c",
   "metadata": {},
   "source": [
    "Filter the dataframe using a regular expression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae102e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "urllib.request.urlretrieve(\"https://github.com/thomasnield/anaconda_intro_to_sql/blob/main/company_operations.db?raw=true\", \"company_operations.db\")\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "\n",
    "df[df[\"ADDRESS\"].str.match(r\"^[0-9]{3}\\s\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
